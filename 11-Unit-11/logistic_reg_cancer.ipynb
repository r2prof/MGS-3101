{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed221ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00c53fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"breast_cancer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60519f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the combined DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf812de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Preprocess the dataset\n",
    "# Replace missing values (marked as '?') with NaN and drop rows with missing values\n",
    "df.replace('?', pd.NA, inplace=True)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1653667d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8b1d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the 'Class' column: 2 (benign) -> 0, 4 (malignant) -> 1\n",
    "df['Class'] = df['Class'].map({2: 0, 4: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dc858b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b365b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Define features (X) and target variable (y)\n",
    "X = df.drop(columns=['Class'])  # All features except the target\n",
    "y = df['Class']  # Target variable (0: benign, 1: malignant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e13aa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6947cd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0937d745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Train logistic regression model\n",
    "model = LogisticRegression(max_iter=10000, random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52c44ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: # Make predictions\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef2668d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1671ce96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Print results\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print('Confusion Matrix:\\n', conf_matrix)\n",
    "print('Classification Report:\\n', class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fe5ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: Visualizing confusion matrix\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36d5b95",
   "metadata": {},
   "source": [
    "#### Logistic Regression Results Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994ed0de",
   "metadata": {},
   "source": [
    "##### 1. Accuracy Score\n",
    "**Formula:**\n",
    "$$Accuracy = \\frac{TP + TN}{TP + TN + FP + FN}$$\n",
    "\n",
    "The accuracy score represents the proportion of correctly predicted instances.\n",
    "- **High Accuracy (close to 1.0 or 100%)** → The model performs well.\n",
    "- **Low Accuracy (<70%)** → The model may need further tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e94daf1",
   "metadata": {},
   "source": [
    "##### 2. Confusion Matrix\n",
    "**Structure:**\n",
    "\n",
    "| Actual \\ Predicted | Predicted Negative (0) | Predicted Positive (1) |\n",
    "|--------------------|-----------------------|-----------------------|\n",
    "| **Actual Negative (0)** | True Negative (TN) | False Positive (FP) |\n",
    "| **Actual Positive (1)** | False Negative (FN) | True Positive (TP) |\n",
    "\n",
    "- **True Positives (TP):** Correctly classified cancerous cases.\n",
    "- **True Negatives (TN):** Correctly classified non-cancerous cases.\n",
    "- **False Positives (FP):** Non-cancerous cases misclassified as cancerous (**Type I error**).\n",
    "- **False Negatives (FN):** Cancerous cases misclassified as non-cancerous (**Type II error** – more serious in medical cases)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a39e07e",
   "metadata": {},
   "source": [
    "##### Example Output:\n",
    "```\n",
    "Confusion Matrix:\n",
    "[[90  5]\n",
    " [ 3 80]]\n",
    "```\n",
    "- **90 TN**, **5 FP**, **3 FN**, **80 TP**.\n",
    "- **Low FN count** is crucial for medical diagnoses to avoid missing cancer cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f69869",
   "metadata": {},
   "source": [
    "#### 3. Classification Report\n",
    "Provides **Precision, Recall, F1-score, and Support** for each class.\n",
    "\n",
    "##### Key Metrics:\n",
    "- **Precision:** Measures how many predicted positive cases were actually positive.\n",
    "  $$Precision = \\frac{TP}{TP + FP}$$\n",
    "\n",
    "  - **High Precision** → Fewer false positives.\n",
    "\n",
    "- **Recall (Sensitivity):** Measures how many actual positive cases were correctly identified.\n",
    "  $$Recall = \\frac{TP}{TP + FN}$$\n",
    "  \n",
    "  - **High Recall** → Fewer false negatives.\n",
    "\n",
    "- **F1-score:** The harmonic mean of precision and recall.\n",
    "  $$F1 = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}$$\n",
    "  - A good balance between precision and recall.\n",
    "\n",
    "- **Support:** Number of actual occurrences of each class in the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51f810e",
   "metadata": {},
   "source": [
    "##### Example Output:\n",
    "```\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "         0       0.95      0.94      0.94       95\n",
    "         1       0.92      0.94      0.93       83\n",
    "```\n",
    "- **Class 0 (Benign Tumor)**: Precision = 95%, Recall = 94%.\n",
    "- **Class 1 (Malignant Tumor)**: Precision = 92%, Recall = 94%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f0c607",
   "metadata": {},
   "source": [
    "##### 4. Confusion Matrix Visualization\n",
    "```python\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "- Darker blue shades in **TP/TN cells** indicate strong classification performance.\n",
    "- High **FP/FN values** may indicate the need for adjustments (e.g., changing the decision threshold)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27948c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8933b7",
   "metadata": {},
   "source": [
    "##### Final Thoughts\n",
    "- **High accuracy, precision, recall, and F1-score indicate a well-performing model.**\n",
    "- **If FN is high, increasing recall is important (e.g., lowering the decision threshold).**\n",
    "- **Confusion matrix visualization helps assess misclassification patterns.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61df569",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ce1993",
   "metadata": {},
   "source": [
    "##### The End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
